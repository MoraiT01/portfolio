# Architecture Overview

Each part of HAnS is running in an own [Docker](https://www.docker.com/) container.
The container name is reflected in the folder structure of the repository and in the figure below:
![Overview](./docs/images/overview.png "Overview")
The repository contains the following subfolders:

- [`frontend`](./frontend/): contains the web service frontend
- [`backend`](./backend/): contains the media, asset and meta databases and the search engine
- [`ml-backend`](./ml-backend/): contains the machine learning backend (ml-backend)

Each directory contains an own [Docker Compose](https://docs.docker.com/compose/) file.

## Frontend

The frontend is a docker container `hans-frontend-web` which contains the following components:

- [Apache](https://apache.org/) is used as webserver and for interacting with DFN AAI for shibboleth authorization

- [Flask](https://palletsprojects.com/p/flask/) is used as
  [WSGI](https://wsgi.readthedocs.io/) web application framework

- [Vue.js](https://vuejs.org/) is used to create the progressive web user interface

## Backend

The media storage and the related meta data and search functionality is provided by docker containers:

- adminer:
  - [Adminer](https://www.adminer.org/en/) is used for the administration (mainly inspection) of the backend databases

- assetdb:
  - Permanent storage for slides, transcripts, extracted audio data (raw audio),
    and other assets produced by an airflow DAG workflow run
  - [MinIO](https://min.io) is used as object storage

- mediadb:
  - Store media objects (audio/video files) and corresponding media presentation description (MPD) files for streaming
  - Streams will be provided using
    [Dynamic Adaptive Streaming over HTTP (DASH)](https://de.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP)
  - [MinIO](https://min.io) is used as object storage

- metadb:
  - Main database
  - Keep track of the media objects in mediadb and the related assets in assetdb
  - Contains meta data generated by [Apache Airflow](https://airflow.apache.org/) DAG workflows
  - [MongoDB](https://www.mongodb.com) is used to store the meta data

- searchengine:
  - Search for topics or words in media objects
  - [OpenSearch](https://opensearch.org/)

- searchengine-dashboard:
  - Visualize search engine data
  - [OpenSearch-Dashboards](https://opensearch.org/docs/latest/dashboards/index/)

## Machine Learning Backend (ml-backend)

The machine learning backend (ml-backend) is powered by [Apache Airflow](https://airflow.apache.org/) (airflow).

Machine learning tasks and other required tasks, e.g. conversion,
are organized in workflows as Directed Acyclic Graphs (DAGs).
The DAGs used for HAnS reside in the [`ml-backend/dags`](./ml-backend/dags/) folder, for more details about the
processing DAGs and related docker operators see [DAGs](./ml-backend/README.md#directed-acyclic-graphs-dags).

The ml-backend contains the following docker containers:

- ariflow:
  - [Apache Airflow](https://airflow.apache.org/) docker base image
  - The following docker services are created by using this docker image in the ml-backend
    [Docker Compose](./ml-backend/docker-compose.yaml) file:
    - airflow-webserver
    - airflow-scheduler
    - airflow-worker
    - airflow-triggerer
    - airflow-init
    - airflow-cli
    - airflow-flower:
      - [Flower](https://flower.readthedocs.io/en/latest/) is a web based tool for monitoring and administrating
        Celery clusters
  - For further details, see
    [Running Airflow in Docker](https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#docker-compose-yaml)

- airflow-adminer:
  - [Adminer](https://www.adminer.org/en/) is used for the administration (mainly inspection)
    of the ml-backend databases

- airflow-docker-proxy:
  - Provides access for airflow to the host docker engine to run airflow docker operator tasks

- airflow-postgresql:
  - [PostgreSQL](https://www.postgresql.org/) main database used by airflow

- airflow-redis:
  - [Redis](https://redis.io/) is by airflow to manage DAGs and task execution

- assetdb-temp:
  - Temporary storage for slides, transcripts, extracted audio data (raw audio),
    and other assets produced by airflow operator tasks
  - [MinIO](https://min.io) is used as object storage

Other docker container which are created and used in airflow DAGs are located in
[`ml-backend/dags/docker_jobs`](./ml-backend/dags/docker_jobs).
